{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPXwrZyi5xx2MtEdfllG/bP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303a52371/GENERATIVE_AI_2025/blob/main/2303A52371_GEN_AI_ASS_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. (1 ponto) Design a simple ANN architecture with one input and one output layer (no hidden layer). Assume a linear activation function in the output layer.\n",
        "• Write Python code for a backpropagation algorithm with gradient descent optimization to\n",
        "update weights and bias parameters of the ANN model with training data shown in Table\n",
        "1.\n",
        "• Calculate the mean square error with training and testing data shown in Table 2.\n",
        "• Write Python code that reads the input data [x1, x2, and x3] from the user. Predict the\n",
        "output with deployed ANN model"
      ],
      "metadata": {
        "id": "iTtfEGe3yegc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGW3HLuukhzg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e44e489-6dec-4664-ce1c-af574aa0243e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Training MSE: 1.9464275661606958\n",
            "Epoch 100, Training MSE: 0.004655464426168567\n",
            "Epoch 200, Training MSE: 0.0010661957967921635\n",
            "Epoch 300, Training MSE: 0.0009215229329360209\n",
            "Epoch 400, Training MSE: 0.0008022814419407457\n",
            "Epoch 500, Training MSE: 0.0006997210575911438\n",
            "Epoch 600, Training MSE: 0.0006114936039018685\n",
            "Epoch 700, Training MSE: 0.0005355894118269312\n",
            "Epoch 800, Training MSE: 0.00047028070765946597\n",
            "Epoch 900, Training MSE: 0.0004140820490617331\n",
            "Test MSE: 0.0004344121379243163\n",
            "Enter x1: 0.6\n",
            "Enter x2: 0.7\n",
            "Enter x3: 0.8\n",
            "Predicted output: 0.42091114336505064\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.44"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "import numpy as np\n",
        "X_train = np.array([[0.1, 0.2, 0.3],\n",
        "                    [0.2, 0.3, 0.4],\n",
        "                    [0.3, 0.4, 0.5],\n",
        "                    [0.5, 0.6, 0.7],\n",
        "                    [0.1, 0.3, 0.5],\n",
        "                    [0.2, 0.4, 0.6],\n",
        "                    [0.3, 0.5, 0.7],\n",
        "                    [0.4, 0.6, 0.8],\n",
        "                    [0.5, 0.7, 0.1]])\n",
        "y_train = np.array([0.14, 0.20, 0.26, 0.38, 0.22, 0.28, 0.34, 0.40, 0.22])\n",
        "X_test = np.array([[0.6, 0.7, 0.8],\n",
        "                   [0.7, 0.8, 0.9]])\n",
        "y_test = np.array([0.44, 0.50])\n",
        "w = np.random.randn(3)\n",
        "b = np.random.randn(1)\n",
        "learning_rate = 0.01\n",
        "epochs = 1000\n",
        "def mean_squared_error(y_true, y_pred):\n",
        "    return np.mean((y_true - y_pred) ** 2)0.8\n",
        "for epoch in range(epochs):\n",
        "    y_pred_train = np.dot(X_train, w) + b\n",
        "    error = y_pred_train - y_train\n",
        "    dw = (2 / X_train.shape[0]) * np.dot(X_train.T, error)\n",
        "    db = (2 / X_train.shape[0]) * np.sum(error)\n",
        "    w -= learning_rate * dw\n",
        "    b -= learning_rate * db\n",
        "    if epoch % 100 == 0:\n",
        "        mse_train = mean_squared_error(y_train, y_pred_train)\n",
        "        print(f'Epoch {epoch}, Training MSE: {mse_train}')\n",
        "y_pred_test = np.dot(X_test, w) + b\n",
        "mse_test = mean_squared_error(y_test, y_pred_test)\n",
        "print(f'Test MSE: {mse_test}')\n",
        "def predict_user_input():\n",
        "    x1 = float(input(\"Enter x1: \"))\n",
        "    x2 = float(input(\"Enter x2: \"))\n",
        "    x3 = float(input(\"Enter x3: \"))\n",
        "    prediction = np.dot([x1, x2, x3], w) + b\n",
        "    print(f'Predicted output: {prediction[0]}')\n",
        "predict_user_input()\n",
        "0.44"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. (1 ponto) Design a simple ANN architecture with one input and one output layer (no hidden\n",
        "layer). Assume a sigmoid activation function shown in the equation 1 in the output layer.\n",
        "f (x) = 1\n",
        "1 + e−x (1)\n",
        "• Write Python code for a backpropagation algorithm with gradient descent optimization to\n",
        "update weights and bias parameters of the ANN model with training data shown in Table"
      ],
      "metadata": {
        "id": "7_HH0ysty4oU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array([\n",
        "    [0.1, 0.2, 0.3],\n",
        "    [0.2, 0.3, 0.4],\n",
        "    [0.3, 0.4, 0.5],\n",
        "    [0.5, 0.6, 0.7],\n",
        "    [0.1, 0.3, 0.5],\n",
        "    [0.2, 0.4, 0.6],\n",
        "    [0.3, 0.5, 0.7],\n",
        "    [0.4, 0.6, 0.8],\n",
        "    [0.5, 0.7, 0.1]\n",
        "])\n",
        "\n",
        "y_train = np.array([0.5349, 0.5498, 0.5646, 0.5939, 0.5548, 0.5695, 0.5842, 0.5987, 0.5548])\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return sigmoid(x) * (1 - sigmoid(x))\n",
        "\n",
        "weights = np.random.randn(3)\n",
        "bias = np.random.randn(1)\n",
        "\n",
        "learning_rate = 0.01\n",
        "epochs = 1000\n",
        "\n",
        "def mse_loss(y_true, y_pred):\n",
        "    return np.mean((y_true - y_pred) ** 2)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    y_pred = sigmoid(X_train.dot(weights) + bias)\n",
        "    loss = mse_loss(y_train, y_pred)\n",
        "    dL_dw = -2 * X_train.T.dot((y_train - y_pred) * sigmoid_derivative(y_pred)) / len(y_train)\n",
        "    dL_db = -2 * np.sum((y_train - y_pred) * sigmoid_derivative(y_pred)) / len(y_train)\n",
        "    weights -= learning_rate * dL_dw\n",
        "    bias -= learning_rate * dL_db\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss}\")\n",
        "\n",
        "X_test = np.array([\n",
        "    [0.6, 0.7, 0.8],\n",
        "    [0.7, 0.8, 0.9]\n",
        "])\n",
        "\n",
        "y_test = np.array([0.6083, 0.6225])\n",
        "\n",
        "y_test_pred = sigmoid(X_test.dot(weights) + bias)\n",
        "test_loss = mse_loss(y_test, y_test_pred)\n",
        "\n",
        "print(\"\\nTest Loss (MSE):\", test_loss)\n",
        "\n",
        "x1 = float(input(\"Enter value for x1: \"))\n",
        "x2 = float(input(\"Enter value for x2: \"))\n",
        "x3 = float(input(\"Enter value for x3: \"))\n",
        "\n",
        "user_input = np.array([x1, x2, x3])\n",
        "y_pred_user = sigmoid(user_input.dot(weights) + bias)\n",
        "print(f\"Predicted output: {y_pred_user}\")\n",
        "0.6083"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMNTOIi5vA4D",
        "outputId": "0bf3e23f-df5f-41c3-de72-27d5ca7da193"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.001955721392879596\n",
            "Epoch 100, Loss: 0.0014931030921248216\n",
            "Epoch 200, Loss: 0.0011702932821112354\n",
            "Epoch 300, Loss: 0.0009443882076764112\n",
            "Epoch 400, Loss: 0.0007857757951571349\n",
            "Epoch 500, Loss: 0.0006739783466673493\n",
            "Epoch 600, Loss: 0.0005948063280888574\n",
            "Epoch 700, Loss: 0.0005384080946456135\n",
            "Epoch 800, Loss: 0.0004979311195987253\n",
            "Epoch 900, Loss: 0.0004686009110341957\n",
            "\n",
            "Test Loss (MSE): 0.0010356333141435773\n",
            "Enter value for x1: 0.6\n",
            "Enter value for x2: 0.7\n",
            "Enter value for x3: 0.8\n",
            "Predicted output: [0.57881267]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6083"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    }
  ]
}