{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOsRueT43r3Up+ch23W85tD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303a52371/GENERATIVE_AI_2025/blob/main/2303A52371_GEN_AI_ASS_3_ipynb_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.**(1 ponto) Write Python code without using any libraries to find the value of x at which the\n",
        "function f(x) shown in equation (1) has minimum value. Consider Gradient Descent Algorithm.**\n",
        "f (x) = 5x4 + 3x2 + 10"
      ],
      "metadata": {
        "id": "Lx8kensHpsdD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpzXz61zmtV-",
        "outputId": "5c4852a2-3901-4223-8159-0e50eacb681d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum value of x: 0\n"
          ]
        }
      ],
      "source": [
        "def f(x):\n",
        "    return 5*x**4 + 3*x**2 + 10\n",
        "def grad_f(x):\n",
        "    return 20*x**3 + 6*x\n",
        "def gradient_descent(f, grad_f, learning_rate=0.01, initial_guess=0, max_iter=1000, tol=1e-6):\n",
        "    x = initial_guess\n",
        "    for i in range(max_iter):\n",
        "        gradient = grad_f(x)\n",
        "        new_x = x - learning_rate * gradient\n",
        "        if abs(new_x - x) < tol:\n",
        "            break\n",
        "        x = new_x\n",
        "    return x\n",
        "x_min = gradient_descent(f, grad_f)\n",
        "print(\"Minimum value of x:\", x_min)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.**(1 ponto) Write Python code without using any libraries to find the value of x and y at which the\n",
        "function g(x,y) shown in equation (2) has minimum value. Consider Gradient Descent Algorithm.**\n",
        "f (x) = 3x2 + 5e−y + 10"
      ],
      "metadata": {
        "id": "nckNwMZup_r6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def g(x, y):\n",
        "    return 3*x**2 + 5*math.exp(-y) + 10\n",
        "def grad_g_x(x, y):\n",
        "    return 6*x\n",
        "def grad_g_y(x, y):\n",
        "    return -5*math.exp(-y)\n",
        "def gradient_descent_2d(f, grad_fx, grad_fy, learning_rate=0.01, initial_guess_x=0, initial_guess_y=0, max_iter=1000, tol=1e-6):\n",
        "    x, y = initial_guess_x, initial_guess_y\n",
        "    for i in range(max_iter):\n",
        "        gradient_x = grad_fx(x, y)\n",
        "        gradient_y = grad_fy(x, y)\n",
        "        new_x = x - learning_rate * gradient_x\n",
        "        new_y = y - learning_rate * gradient_y\n",
        "        if abs(new_x - x) < tol and abs(new_y - y) < tol:\n",
        "            break\n",
        "        x, y = new_x, new_y\n",
        "    return x, y\n",
        "x_min, y_min = gradient_descent_2d(g, grad_g_x, grad_g_y)\n",
        "print(\"Minimum value of x:\", x_min)\n",
        "print(\"Minimum value of y:\", y_min)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJiU6RWTngX5",
        "outputId": "e90d5d9f-e76b-4bae-9da4-1d32aebe29f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum value of x: 0.0\n",
            "Minimum value of y: 3.9337602416246904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.**(1 ponto) Write Python code without using any libraries to find the value of x at which the\n",
        "sigmoid function z(x) shown in equation (3) has minimum value. Consider Gradient Descent\n",
        "Algorithm.**\n",
        "z(x) = 1/\n",
        "1 + e−x"
      ],
      "metadata": {
        "id": "sJQn6b_cqUxE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + math.exp(-x))\n",
        "def grad_sigmoid(x):\n",
        "    z_x = sigmoid(x)\n",
        "    return z_x * (1 - z_x)\n",
        "def gradient_descent_sigmoid(f, grad_f, learning_rate=0.01, initial_guess=0, max_iter=1000, tol=1e-6):\n",
        "    x = initial_guess\n",
        "    for i in range(max_iter):\n",
        "        gradient = grad_f(x)\n",
        "        new_x = x - learning_rate * gradient\n",
        "        if abs(new_x - x) < tol:\n",
        "            break\n",
        "        x = new_x\n",
        "    return x\n",
        "x_min = gradient_descent_sigmoid(sigmoid, grad_sigmoid)\n",
        "print(\"Minimum value of x for sigmoid function:\", x_min)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrRkObGpnkkL",
        "outputId": "7c4a90cc-26de-41ec-e68f-a3d0b2a7bcc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum value of x for sigmoid function: -1.8618354629020137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. **(1 ponto) Write Python code without using any libraries to find the value of optimal values of\n",
        "model parameters M and C such that the model’s Square Error Value shown in equation 4 will\n",
        "be minimum. It means model gives output close to expected**"
      ],
      "metadata": {
        "id": "YH8q2LT1qsAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_values = [1, 2, 3, 4, 5]\n",
        "expected_output = [2, 4, 6, 8, 10]\n",
        "def predicted_output(M, C, x):\n",
        "    return M * x + C\n",
        "def grad_M(x_values, expected_output, M, C):\n",
        "    grad_M = 0\n",
        "    for x, expected in zip(x_values, expected_output):\n",
        "        grad_M += -2 * (expected - predicted_output(M, C, x)) * x\n",
        "    return grad_M\n",
        "def grad_C(x_values, expected_output, M, C):\n",
        "    grad_C = 0\n",
        "    for x, expected in zip(x_values, expected_output):\n",
        "        grad_C += -2 * (expected - predicted_output(M, C, x))\n",
        "    return grad_C\n",
        "def gradient_descent_linear(learning_rate=0.01, initial_M=0, initial_C=0, max_iter=1000, tol=1e-6):\n",
        "    M, C = initial_M, initial_C\n",
        "    for i in range(max_iter):\n",
        "        gradient_M = grad_M(x_values, expected_output, M, C)\n",
        "        gradient_C = grad_C(x_values, expected_output, M, C)\n",
        "        new_M = M - learning_rate * gradient_M\n",
        "        new_C = C - learning_rate * gradient_C\n",
        "        if abs(new_M - M) < tol and abs(new_C - C) < tol:\n",
        "            break\n",
        "        M, C = new_M, new_C\n",
        "    return M, C\n",
        "M_optimal, C_optimal = gradient_descent_linear()\n",
        "print(\"Optimal value of M:\", M_optimal)\n",
        "print(\"Optimal value of C:\", C_optimal)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tl368fysnoZk",
        "outputId": "63768bd0-5ca3-499f-bdaf-9eba6aed34e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal value of M: 1.9999838833131243\n",
            "Optimal value of C: 5.818635341790548e-05\n"
          ]
        }
      ]
    }
  ]
}